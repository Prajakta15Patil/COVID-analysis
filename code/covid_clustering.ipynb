{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.51 s, sys: 586 ms, total: 2.09 s\n",
      "Wall time: 1.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.29 s, sys: 550 ms, total: 4.84 s\n",
      "Wall time: 4.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "path = '/home/prajakta/Documents/SharpestMinds/COVID-analysis/data/*.json'\n",
    "files = glob.glob(path)\n",
    "papers = []\n",
    "for file in files:\n",
    "    with open(file) as json_file:\n",
    "            text = json.load(json_file)\n",
    "            papers.append([text['paper_id'],text['title'], text['bodytext'], text['abstract']])\n",
    "data = pd.DataFrame(papers, columns = ['paper_id','title', 'bodytext', 'abstract'])\n",
    "filter = data.abstract != \"\"\n",
    "data = data[filter]\n",
    "data['len_bt'] = data.bodytext.map(lambda x: len(x.split(\" \")))\n",
    "data['len_ab'] = data.abstract.map(lambda x: len(x.split(\" \")))\n",
    "data.query('len_bt <= 10000 and len_ab <= 500', inplace = True)\n",
    "#first_10 = data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(bodytext):\n",
    "    cleaned = list()\n",
    "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    # prepare translation table \n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for word in bodytext:\n",
    "        if word.is_stop == False:\n",
    "            words = str(word.lemma_)       \n",
    "            words = words.lower()\n",
    "            words = words.translate(table)\n",
    "            words = re_print.sub('', words) \n",
    "            if words.isalpha() == True:\n",
    "                cleaned.append(words)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "ab_str = []\n",
    "for i in range(len(data)):\n",
    "    abstract = nlp(data.iloc[i].abstract)\n",
    "    ab_clean = clean_text(abstract)\n",
    "    ab_str.append((' ').join(ab_clean))\n",
    "data['ab_clean'] = ab_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>bodytext</th>\n",
       "      <th>abstract</th>\n",
       "      <th>len_bt</th>\n",
       "      <th>len_ab</th>\n",
       "      <th>ab_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17413f651645c2b9c92555e9ce1404b9290eccab</td>\n",
       "      <td>Non-human primate orthologues of TMPRSS2 cleav...</td>\n",
       "      <td>a1111111111 a1111111111 a1111111111 a11111111...</td>\n",
       "      <td>The cellular serine protease TMPRSS2, a membe...</td>\n",
       "      <td>3544</td>\n",
       "      <td>267</td>\n",
       "      <td>cellular serine protease member type ii transm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ab8c1e32b66b02cd703799df3d2ee37a1cb369b7</td>\n",
       "      <td>Enhanced protection in mice induced by immuniz...</td>\n",
       "      <td>Middle East respiratory syndrome coronavirus ...</td>\n",
       "      <td>The persistent public health threat of infect...</td>\n",
       "      <td>4250</td>\n",
       "      <td>224</td>\n",
       "      <td>persistent public health threat infection midd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>685efeb0ad4c214b8295dc4f723c3269464772d8</td>\n",
       "      <td>viruses Isolation of a Novel Fusogenic Orthore...</td>\n",
       "      <td>Bats have been increasingly associated with e...</td>\n",
       "      <td>We report on the isolation of a novel fusogen...</td>\n",
       "      <td>4515</td>\n",
       "      <td>155</td>\n",
       "      <td>report isolation novel fusogenic orthoreovirus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>09ccb3b9fece55e72c3acb85c4259de62a9c9e0c</td>\n",
       "      <td>Association of herd BRSV and BHV-1 seroprevale...</td>\n",
       "      <td>Bovine respiratory disease (BRD) incorporates...</td>\n",
       "      <td>Background: The aim of this study was to dete...</td>\n",
       "      <td>4393</td>\n",
       "      <td>275</td>\n",
       "      <td>background aim study detect association bovine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>93d080273b1f33330243dd140a35ba890ddd2973</td>\n",
       "      <td>The determinants and consequences of adult nur...</td>\n",
       "      <td>Nurses leaving their jobs or leaving the prof...</td>\n",
       "      <td>Background: Nurses leaving their jobs and the...</td>\n",
       "      <td>7160</td>\n",
       "      <td>298</td>\n",
       "      <td>background nurse leave job profession issue in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   paper_id  \\\n",
       "0  17413f651645c2b9c92555e9ce1404b9290eccab   \n",
       "3  ab8c1e32b66b02cd703799df3d2ee37a1cb369b7   \n",
       "4  685efeb0ad4c214b8295dc4f723c3269464772d8   \n",
       "5  09ccb3b9fece55e72c3acb85c4259de62a9c9e0c   \n",
       "7  93d080273b1f33330243dd140a35ba890ddd2973   \n",
       "\n",
       "                                               title  \\\n",
       "0  Non-human primate orthologues of TMPRSS2 cleav...   \n",
       "3  Enhanced protection in mice induced by immuniz...   \n",
       "4  viruses Isolation of a Novel Fusogenic Orthore...   \n",
       "5  Association of herd BRSV and BHV-1 seroprevale...   \n",
       "7  The determinants and consequences of adult nur...   \n",
       "\n",
       "                                            bodytext  \\\n",
       "0   a1111111111 a1111111111 a1111111111 a11111111...   \n",
       "3   Middle East respiratory syndrome coronavirus ...   \n",
       "4   Bats have been increasingly associated with e...   \n",
       "5   Bovine respiratory disease (BRD) incorporates...   \n",
       "7   Nurses leaving their jobs or leaving the prof...   \n",
       "\n",
       "                                            abstract  len_bt  len_ab  \\\n",
       "0   The cellular serine protease TMPRSS2, a membe...    3544     267   \n",
       "3   The persistent public health threat of infect...    4250     224   \n",
       "4   We report on the isolation of a novel fusogen...    4515     155   \n",
       "5   Background: The aim of this study was to dete...    4393     275   \n",
       "7   Background: Nurses leaving their jobs and the...    7160     298   \n",
       "\n",
       "                                            ab_clean  \n",
       "0  cellular serine protease member type ii transm...  \n",
       "3  persistent public health threat infection midd...  \n",
       "4  report isolation novel fusogenic orthoreovirus...  \n",
       "5  background aim study detect association bovine...  \n",
       "7  background nurse leave job profession issue in...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 788 ms, sys: 7.96 ms, total: 796 ms\n",
      "Wall time: 796 ms\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.03 GiB for an array with shape (8059, 33749) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4ee34443bbc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tfidf_matrix = tfidf_vectorizer.fit_transform(data.ab_clean) #fit the vectorizer to synopses'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mab_clean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#print(tfidf_matrix.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/covid_env/lib/python3.8/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m             \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Output array must be C or F contiguous'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/covid_env/lib/python3.8/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 2.03 GiB for an array with shape (8059, 33749) and data type float64"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "#define vectorizer parameters\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "%time tfidf_matrix = tfidf_vectorizer.fit_transform(data.ab_clean) #fit the vectorizer to synopses\n",
    "pd.DataFrame(tfidf_vectorizer.transform(data.ab_clean).toarray(), columns = sorted(tfidf_vectorizer.vocabulary_.keys()))\n",
    "\n",
    "#print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist = 1 - cosine_similarity(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 5\n",
    "\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "%time km.fit(tfidf_matrix)\n",
    "\n",
    "data['clusters'] = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = pd.DataFrame(np.sort(data.clusters.value_counts()), columns = ['num_papers'])\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "vocab_frame = pd.DataFrame(tfidf_vectorizer.vocabulary_.keys())\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "print()\n",
    "#sort cluster centers by proximity to centroid\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    "\n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d words:\" % i, end='')\n",
    "    \n",
    "    for ind in order_centroids[i, :10]: #replace 6 with n words per cluster\n",
    "        print(' %s' % vocab_frame.iloc[ind].tolist()[0], end=',')\n",
    "    print() #add whitespace\n",
    "    print() #add whitespace\n",
    "    \n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query('clusters == 2', inplace = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
