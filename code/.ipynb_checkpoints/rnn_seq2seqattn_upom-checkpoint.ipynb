{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.7 s, sys: 1.08 s, total: 4.78 s\n",
      "Wall time: 5.78 s\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense,Flatten, Concatenate, TimeDistributed, Bidirectional, Attention, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow import TensorShape\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.1 ms, sys: 4.16 ms, total: 20.3 ms\n",
      "Wall time: 25.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "path = './data/*.json'\n",
    "files = glob.glob(path)\n",
    "papers = []\n",
    "for file in files:\n",
    "    with open(file) as json_file:\n",
    "            text = json.load(json_file)\n",
    "            papers.append([text['paper_id'], text['bodytext'], text['abstract']])\n",
    "data = pd.DataFrame(papers, columns = ['paper_id', 'bodytext', 'abstract'])\n",
    "filter = data.abstract != \"\"\n",
    "data = data[filter][:15]\n",
    "data['len_bt'] = data.bodytext.map(lambda x: len(x.split(\" \")))\n",
    "data['len_ab'] = data.abstract.map(lambda x: len(x.split(\" \")))\n",
    "data.query('len_bt <= 10000 and len_ab <= 500', inplace = True)\n",
    "#first_10 = data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len_bt</th>\n",
       "      <th>len_ab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4821.769231</td>\n",
       "      <td>207.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2004.878099</td>\n",
       "      <td>66.837346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1311.000000</td>\n",
       "      <td>107.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3884.000000</td>\n",
       "      <td>175.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4655.000000</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5629.000000</td>\n",
       "      <td>242.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9002.000000</td>\n",
       "      <td>345.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            len_bt      len_ab\n",
       "count    13.000000   13.000000\n",
       "mean   4821.769231  207.307692\n",
       "std    2004.878099   66.837346\n",
       "min    1311.000000  107.000000\n",
       "25%    3884.000000  175.000000\n",
       "50%    4655.000000  191.000000\n",
       "75%    5629.000000  242.000000\n",
       "max    9002.000000  345.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x14bf89278>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data.len_bt,data.len_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(bodytext):\n",
    "    cleaned = list()\n",
    "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    # prepare translation table \n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for word in bodytext:\n",
    "        words = str(word)       \n",
    "        words = words.lower()\n",
    "        words = words.translate(table)\n",
    "        words = re_print.sub('', words) \n",
    "        if words.isalpha() == True:\n",
    "            cleaned.append(words)\n",
    "    cleaned.insert(0, '<start>')\n",
    "    cleaned.append('<end>')\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "bt_vector = list()\n",
    "bt_list = []\n",
    "ab_list = []\n",
    "for i in range(len(data)):\n",
    "    bodytext = nlp(data.iloc[i].bodytext)\n",
    "    bt_clean = clean_text(bodytext)\n",
    "    bt_list.append(bt_clean)\n",
    "    \n",
    "    abstract = nlp(data.iloc[i].abstract)\n",
    "    ab_clean = clean_text(abstract)\n",
    "    ab_list.append(ab_clean)\n",
    "com_list = ab_list + bt_list\n",
    "    #c_papers.append(papers)\n",
    "bt_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "bt_tokenizer.fit_on_texts(com_list)\n",
    "data_bt = bt_tokenizer.texts_to_sequences(bt_list)\n",
    "data_ab = bt_tokenizer.texts_to_sequences(ab_list)\n",
    "\n",
    "longest_seq = max(max([len(x) for x in data_bt]), max([len(x) for x in data_ab]))\n",
    "#x_voc_size = max([len(x) for x in data_bt])#, max([len(x) for x in data_ab]))\n",
    "#y_voc_size = max([len(y) for y in data_ab])\n",
    "data_bt = tf.keras.preprocessing.sequence.pad_sequences(data_bt,padding='post', maxlen = longest_seq)\n",
    "data_ab = tf.keras.preprocessing.sequence.pad_sequences(data_ab,padding='post', maxlen = longest_seq) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_len(tensor):\n",
    "    #print( np.argmax([len(t) for t in tensor]))\n",
    "    return max( len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train,  X_test, Y_train, Y_test = train_test_split(data_bt,data_ab,test_size=0.2)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "BATCH_SIZE = 5\n",
    "BUFFER_SIZE = len(X_train)\n",
    "steps_per_epoch = BUFFER_SIZE//BATCH_SIZE\n",
    "embedding_dims = 256\n",
    "rnn_units = 1024\n",
    "dense_units = 1024\n",
    "Dtype = tf.float32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(bt_tokenizer.word_index)+1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_initial_state():\n",
    "        return [tf.zeros((BATCH_SIZE, rnn_units)), tf.zeros((BATCH_SIZE, rnn_units))]\n",
    "encoder_initial_cell_state = initialize_initial_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENCODER\n",
    "class EncoderNetwork(tf.keras.Model):\n",
    "    def __init__(self,input_vocab_size,embedding_dims, rnn_units ):\n",
    "        super().__init__()\n",
    "        self.encoder_embedding = tf.keras.layers.Embedding(input_dim=input_vocab_size,\n",
    "                                                           output_dim=embedding_dims)\n",
    "        self.encoder_rnnlayer = tf.keras.layers.LSTM(rnn_units,return_sequences=True, \n",
    "                                                     return_state=True )\n",
    "    \n",
    "#DECODER\n",
    "class DecoderNetwork(tf.keras.Model):\n",
    "    def __init__(self,output_vocab_size, embedding_dims, rnn_units):\n",
    "        super().__init__()\n",
    "        self.decoder_embedding = tf.keras.layers.Embedding(input_dim=output_vocab_size,\n",
    "                                                           output_dim=embedding_dims) \n",
    "        self.dense_layer = tf.keras.layers.Dense(output_vocab_size)\n",
    "        self.decoder_rnncell = tf.keras.layers.LSTMCell(rnn_units)\n",
    "        # Sampler\n",
    "        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "        # Create attention mechanism with memory = None\n",
    "        self.attention_mechanism = self.build_attention_mechanism(dense_units,None,BATCH_SIZE*[longest_seq])\n",
    "        self.rnn_cell =  self.build_rnn_cell(BATCH_SIZE)\n",
    "        self.decoder = tfa.seq2seq.BasicDecoder(self.rnn_cell, sampler= self.sampler,\n",
    "                                                output_layer=self.dense_layer)\n",
    "\n",
    "    def build_attention_mechanism(self, units,memory, memory_sequence_length):\n",
    "        return tfa.seq2seq.LuongAttention(units, memory = memory, \n",
    "                                          memory_sequence_length=memory_sequence_length)\n",
    "        #return tfa.seq2seq.BahdanauAttention(units, memory = memory, memory_sequence_length=memory_sequence_length)\n",
    "\n",
    "    # wrap decodernn cell  \n",
    "    def build_rnn_cell(self, batch_size ):\n",
    "        rnn_cell = tfa.seq2seq.AttentionWrapper(self.decoder_rnncell, self.attention_mechanism,\n",
    "                                                attention_layer_size=dense_units)\n",
    "        return rnn_cell\n",
    "    \n",
    "    def build_decoder_initial_state(self, batch_size, encoder_state,Dtype):\n",
    "        decoder_initial_state = self.rnn_cell.get_initial_state(batch_size = batch_size, \n",
    "                                                                dtype = Dtype)\n",
    "        decoder_initial_state = decoder_initial_state.clone(cell_state=encoder_state) \n",
    "        return decoder_initial_state\n",
    "\n",
    "encoderNetwork = EncoderNetwork(longest_seq,embedding_dims, rnn_units)\n",
    "decoderNetwork = DecoderNetwork(longest_seq,embedding_dims, rnn_units)\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_pred, y):\n",
    "   \n",
    "    #shape of y [batch_size, ty]\n",
    "    #shape of y_pred [batch_size, Ty, output_vocab_size] \n",
    "    sparsecategoricalcrossentropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
    "                                                                                  reduction='none')\n",
    "    loss = sparsecategoricalcrossentropy(y_true=y, y_pred=y_pred)\n",
    "    mask = tf.logical_not(tf.math.equal(y,0))   #output 0 for y=0 else output 1\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss = mask* loss\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss\n",
    "\n",
    "def train_step(input_batch, output_batch,encoder_initial_cell_state):\n",
    "    #initialize loss = 0\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        encoder_emb_inp = encoderNetwork.encoder_embedding(input_batch)\n",
    "        a, a_tx, c_tx = encoderNetwork.encoder_rnnlayer(encoder_emb_inp, \n",
    "                                                        initial_state =encoder_initial_cell_state)\n",
    "\n",
    "        #[last step activations,last memory_state] of encoder passed as input to decoder Network\n",
    "        \n",
    "         \n",
    "        # Prepare correct Decoder input & output sequence data\n",
    "        decoder_input = output_batch[:,:-1] # ignore <end>\n",
    "        #compare logits with timestepped +1 version of decoder_input\n",
    "        decoder_output = output_batch[:,1:] #ignore <start>\n",
    "\n",
    "\n",
    "        # Decoder Embeddings\n",
    "        decoder_emb_inp = decoderNetwork.decoder_embedding(decoder_input)\n",
    "\n",
    "        #Setting up decoder memory from encoder output and Zero State for AttentionWrapperState\n",
    "        decoderNetwork.attention_mechanism.setup_memory(a)\n",
    "        decoder_initial_state = decoderNetwork.build_decoder_initial_state(BATCH_SIZE,\n",
    "                                                                           encoder_state=[a_tx, c_tx],\n",
    "                                                                           Dtype=tf.float32)\n",
    "        \n",
    "        #BasicDecoderOutput        \n",
    "        outputs, _, _ = decoderNetwork.decoder(decoder_emb_inp,initial_state=decoder_initial_state,\n",
    "                                               sequence_length=BATCH_SIZE*[longest_seq-1])\n",
    "\n",
    "        logits = outputs.rnn_output\n",
    "        #Calculate loss\n",
    "\n",
    "        loss = loss_function(logits, decoder_output)\n",
    "\n",
    "    #Returns the list of all layer variables / weights.\n",
    "    variables = encoderNetwork.trainable_variables + decoderNetwork.trainable_variables  \n",
    "    # differentiate loss wrt variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    #grads_and_vars – List of(gradient, variable) pairs.\n",
    "    grads_and_vars = zip(gradients,variables)\n",
    "    optimizer.apply_gradients(grads_and_vars)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "for i in range(1, epochs+1):\n",
    "\n",
    "    encoder_initial_cell_state = initialize_initial_state()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for ( batch , (input_batch, output_batch)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(input_batch, output_batch, encoder_initial_cell_state)\n",
    "        total_loss += batch_loss\n",
    "        if (batch+1)%5 == 0:\n",
    "            print(\"total loss: {} epoch {} batch {} \".format(batch_loss.numpy(), i, batch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.abstract[data.paper_id == '1b8770691fe974dfb269a16db59750370b9c0c21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = tf.math.argmax(summary, axis=1).numpy()\n",
    "words = [bt_tokenizer.index_word[x] for x in indexes if x!=0 ]\n",
    "\" \".join(words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
