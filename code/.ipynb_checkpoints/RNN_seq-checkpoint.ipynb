{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.81 s, sys: 507 ms, total: 2.32 s\n",
      "Wall time: 1.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional, Attention\n",
    "from tensorflow.keras.models import Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.31 s, sys: 572 ms, total: 2.88 s\n",
      "Wall time: 2.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "path = '/home/prajakta/Documents/SharpestMinds/COVID-analysis/data/*.json'\n",
    "files = glob.glob(path)\n",
    "papers = []\n",
    "for file in files:\n",
    "    with open(file) as json_file:\n",
    "            text = json.load(json_file)\n",
    "            papers.append([text['paper_id'], text['bodytext'], text['abstract']])\n",
    "data = pd.DataFrame(papers, columns = ['paper_id', 'bodytext', 'abstract'])\n",
    "filter = data.abstract != \"\"\n",
    "data = data[filter][:15]\n",
    "data['len_bt'] = data.bodytext.map(lambda x: len(x.split(\" \")))\n",
    "data['len_ab'] = data.abstract.map(lambda x: len(x.split(\" \")))\n",
    "data.query('len_bt <= 10000 and len_ab <= 500', inplace = True)\n",
    "#first_10 = data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len_bt</th>\n",
       "      <th>len_ab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4421.928571</td>\n",
       "      <td>236.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1664.263823</td>\n",
       "      <td>76.121794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2062.000000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3556.500000</td>\n",
       "      <td>221.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4096.500000</td>\n",
       "      <td>256.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5369.250000</td>\n",
       "      <td>274.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7861.000000</td>\n",
       "      <td>352.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            len_bt      len_ab\n",
       "count    14.000000   14.000000\n",
       "mean   4421.928571  236.285714\n",
       "std    1664.263823   76.121794\n",
       "min    2062.000000   48.000000\n",
       "25%    3556.500000  221.750000\n",
       "50%    4096.500000  256.500000\n",
       "75%    5369.250000  274.750000\n",
       "max    7861.000000  352.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f9310d23790>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data.len_bt,data.len_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(bodytext):\n",
    "    cleaned = list()\n",
    "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    # prepare translation table \n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for word in bodytext:\n",
    "        words = str(word)       \n",
    "        words = words.lower()\n",
    "        words = words.translate(table)\n",
    "        words = re_print.sub('', words) \n",
    "        if words.isalpha() == True:\n",
    "            cleaned.append(words)\n",
    "    cleaned.insert(0, '<start>')\n",
    "    cleaned.append('<end>')\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "bt_vector = list()\n",
    "bt_list = []\n",
    "ab_list = []\n",
    "for i in range(len(data)):\n",
    "    bodytext = nlp(data.iloc[i].bodytext)\n",
    "    bt_clean = clean_text(bodytext)\n",
    "    bt_list.append(bt_clean)\n",
    "    \n",
    "    abstract = nlp(data.iloc[i].abstract)\n",
    "    ab_clean = clean_text(abstract)\n",
    "    ab_list.append(ab_clean)\n",
    "com_list = ab_list + bt_list\n",
    "    #c_papers.append(papers)\n",
    "bt_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "bt_tokenizer.fit_on_texts(com_list)\n",
    "data_bt = bt_tokenizer.texts_to_sequences(bt_list)\n",
    "data_ab = bt_tokenizer.texts_to_sequences(ab_list)\n",
    "\n",
    "longest_seq = max(max([len(x) for x in data_bt]), max([len(x) for x in data_ab]))\n",
    "x_voc_size = max([len(x) for x in data_bt])#, max([len(x) for x in data_ab]))\n",
    "y_voc_size = max([len(y) for y in data_ab])\n",
    "data_bt = tf.keras.preprocessing.sequence.pad_sequences(data_bt,padding='post', maxlen = x_voc_size)\n",
    "data_ab = tf.keras.preprocessing.sequence.pad_sequences(data_ab,padding='post', maxlen = y_voc_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_len(tensor):\n",
    "    #print( np.argmax([len(t) for t in tensor]))\n",
    "    return max( len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "X_train,  X_test, Y_train, Y_test = train_test_split(data_bt,data_ab,test_size=0.2)\n",
    "BATCH_SIZE = 5\n",
    "BUFFER_SIZE = len(X_train)\n",
    "steps_per_epoch = BUFFER_SIZE//BATCH_SIZE\n",
    "embedding_dims = 256\n",
    "rnn_units = 1024\n",
    "dense_units = 1024\n",
    "Dtype = tf.float32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(bt_tokenizer.word_index)+1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_initial_state():\n",
    "        return [tf.zeros((BATCH_SIZE, rnn_units)), tf.zeros((BATCH_SIZE, rnn_units))]\n",
    "encoder_initial_cell_state = initialize_initial_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#for ( batch , (input_batch, output_batch)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "inputs = keras.Input(shape=(longest_seq,))\n",
    "emb = layers.Embedding(input_dim = vocab_size, output_dim = embedding_dims)(inputs)\n",
    "lstm = layers.LSTM(rnn_units, return_sequences = True, return_state = True)(emb)\n",
    "encoder_states = [lstm[1], lstm[2]]\n",
    "#dense = layers.Dense(vocab_size)(lstm[0])\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None, rnn_units))\n",
    "decoder_lstm = layers.LSTM(rnn_units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = layers.Dense(rnn_units, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "model = keras.Model([inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "#model = keras.Model(inputs=inputs, outputs=dense)    \n",
    "#print(inputs.shape, dense.shape)\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[\"sparse_categorical_accuracy\"], #choose a better metric AUC\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=2, validation_split=0.2)\n",
    "\n",
    "test_scores = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inputs = keras.Input(shape=(longest_seq,))\n",
    "encoder1 = layers.Embedding(vocab_size, 128)(inputs)\n",
    "encoder2 = layers.LSTM(128, return_sequences=True, return_state = True)(encoder1)\n",
    "#outputs = layers.RepeatVector(longest_seq)(encoder2)\n",
    "# decoder output model\n",
    "decoder1 = layers.LSTM(128)(encoder2)\n",
    "outputs = layers.Dense(longest_seq, activation='softmax')(decoder1)\n",
    "\n",
    "# tie it together\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "\n",
    "history = model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=2, validation_split=0.2)\n",
    "\n",
    "inputs.shape, outputs.shape\n",
    "#test_scores = model.evaluate(X_test, Y_test, verbose=1)\n",
    "#print(\"Test loss:\", test_scores[0])\n",
    "#print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 500 \n",
    "\n",
    "# Encoder \n",
    "encoder_inputs = Input(shape=(longest_seq,)) \n",
    "enc_emb = Embedding(x_voc_size, latent_dim,trainable=True)(encoder_inputs) \n",
    "\n",
    "#Preparing LSTM layer 1 \n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
    "\n",
    "#Preparing LSTM layer 2\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "encoder_outputs, state_h, state_c = encoder_lstm2(encoder_output1) \n",
    "\n",
    "#Preparing LSTM layer 3\n",
    "# encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
    "# encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
    "\n",
    "# Decoder layer \n",
    "decoder_inputs = Input(shape=(350,)) \n",
    "dec_emb = Embedding(y_voc_size, latent_dim,trainable=True)(decoder_inputs) \n",
    "#dec_emb = dec_emb_layer(decoder_inputs) \n",
    "\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 350, 500])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #Preparing the Attention Layer\n",
    "# attn_layer = Attention(name='attention_layer') \n",
    "# attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
    "# decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# #Adding the dense layer\n",
    "# decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) \n",
    "# decoder_outputs = decoder_dense(decoder_concat_input) \n",
    "\n",
    "# Prepare the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
    "\n",
    "# Compiling the RNN model\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 7143)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 7143, 500)    3571500     input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 350)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, 7143, 500),  2002000     embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 350, 500)     176000      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   [(None, 7143, 500),  2002000     lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   [(None, 350, 500), ( 2002000     embedding_5[0][0]                \n",
      "                                                                 lstm_7[0][1]                     \n",
      "                                                                 lstm_7[0][2]                     \n",
      "==================================================================================================\n",
      "Total params: 9,753,500\n",
      "Trainable params: 9,753,500\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "in user code:\n\n    /home/prajakta/anaconda3/envs/covid_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    /home/prajakta/anaconda3/envs/covid_env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/prajakta/anaconda3/envs/covid_env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/prajakta/anaconda3/envs/covid_env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/prajakta/anaconda3/envs/covid_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1122 predict_step  **\n        return self(x, training=False)\n    /home/prajakta/anaconda3/envs/covid_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /home/prajakta/anaconda3/envs/covid_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py:717 call\n        return self._run_internal_graph(\n    /home/prajakta/anaconda3/envs/covid_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py:899 _run_internal_graph\n        assert str(id(x)) in tensor_dict, 'Could not compute output ' + str(x)\n\n    AssertionError: Could not compute output Tensor(\"lstm_8/Identity:0\", shape=(None, 350, 500), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-de8b78a67deb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mp_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_bt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/covid_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/anaconda3/envs/covid_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1266\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m             \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/covid_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/covid_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/covid_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 505\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    506\u001b[0m             *args, **kwds))\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/covid_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/covid_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/covid_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2655\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 2657\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2659\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/covid_env/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/covid_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/covid_env/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: in user code:\n\n    /home/prajakta/anaconda3/envs/covid_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    /home/prajakta/anaconda3/envs/covid_env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/prajakta/anaconda3/envs/covid_env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/prajakta/anaconda3/envs/covid_env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/prajakta/anaconda3/envs/covid_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1122 predict_step  **\n        return self(x, training=False)\n    /home/prajakta/anaconda3/envs/covid_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /home/prajakta/anaconda3/envs/covid_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py:717 call\n        return self._run_internal_graph(\n    /home/prajakta/anaconda3/envs/covid_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py:899 _run_internal_graph\n        assert str(id(x)) in tensor_dict, 'Could not compute output ' + str(x)\n\n    AssertionError: Could not compute output Tensor(\"lstm_8/Identity:0\", shape=(None, 350, 500), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "p_data = data_bt[0].reshape(1,-1)\n",
    "summary = model.predict(p_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = tf.math.argmax(summary, axis=1).numpy()\n",
    "words = [bt_tokenizer.index_word[x] for x in indexes ]\n",
    "\" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
